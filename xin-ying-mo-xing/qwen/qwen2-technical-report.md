---
description: Qwen2 系列模型，阿里巴巴大型語言模型和大型多模態模型
---

# Qwen2 Technical Report

## **摘要**

* Qwen2 包含一系列基礎和指令微調的語言模型，參數範圍從 0.5B 到 72B，包括密集模型（featuring dense）和專家混合模型（Mixture-of-Experts）。
* 在語言理解、生成、多語言能力、編碼、數學和推理等多項基準測試中，表現優於大多數先前的開源模型，包括其前身 Qwen1.5，並展現出與專有模型相比具有競爭力的性能。
* 擁有強大的多語言能力，精通約 30 種語言，涵蓋英語、中文、西班牙語、法語、德語、阿拉伯語、俄語、韓語、日語、泰語、越南語等，突出了其多功能性和全球影響力。

## **1.** 簡介（Introduction）

* 在 ChatGPT  發表後 Llama 系列的發布更進一步激發開源社區的興趣，特別是對於 GPT 級別的本地 LLM，隨著 Claude-3 Opus 和 GPT-4o (omni) 先後成為 Chatbot Arena 的佼佼者，Llama-3 也成為最先進的開源模型系列，縮小了與領先專有模型的性能差距，並被廣泛認為達到了 GPT-4 級別。
* 越來越多的有競爭力的 LLM 現在正在追求與 OpenAI 的 GPT 系列類似的進展。其中許多模型，包括 Qwen、Mistral、Gemma 等，都是以開源權重的方式發布的，阿里巴巴陸續推出了 Qwen 系列和 Qwen1.5，並推出了視覺語言模型 Qwen-VL 和音頻語言模型 Qwen-Audio。
* Qwen2 是 Qwen 家族大型語言模型和大型多模態模型的最新成員，基於 Transformer 架構，該模型系列包括基礎語言模型（預先訓練但未與人類偏好保持一致）和指令微調模型（使用適合聊天和代理用途的單輪和多輪指令遵循數據集進行微調）。
* 阿里巴巴發布了四個密集模型，參數計數分別為 5 億、15 億、70 億和 720 億，以及一個具有 570 億參數的專家混合 (MoE) 模型，其中每次啟動 140 億個參數，較小的模型（Qwen2-0.5B 和 Qwen2-1.5B）部署在智能手機、耳機和智能眼鏡等便攜設備上。較大的模型則適合在不同規模的 GPU 上部署。
* 所有模型都經過高質量、大規模數據集的預先訓練，該數據集包含超過 7 萬億個詞，涵蓋了廣泛的領域和語言，與以前的 Qwen 版本相比，Qwen2 包含更廣泛的語言數據，提高了代碼和數學內容的數量和質量。據推測，這種豐富性可以提高 LLM 的推理能力。
* 所有模型都經過監督微調和直接偏好優化 (DPO)，通過從人類反饋中學習，使它們與人類偏好保持一致。這個過程使模型能夠有效地遵循指令。
* 阿里巴巴對 Qwen2 以及一系列基準模型（包括可通過 API 訪問的開源和專有模型）進行了全面評估。Qwen2 在基礎語言能力和指令微調功能的評估中均優於競爭模型。

## **2. 詞彙表和模型（**Tokenizer & Model**）**

### **2.1 詞彙表**

* 與 Qwen 一樣，Qwen2 使用基於字節級字節對編碼的相同詞彙表。值得注意的是，這個詞彙表表現出很高的編碼效率，這一點從它相對於其他詞彙表更好的壓縮率就可以看出，這促進了 Qwen2 的多語言能力。
* 所有大小的模型都使用一個包含 151, 643 個常規詞和 3 個控制詞的通用詞彙表，由於分佈式訓練的考慮，嵌入的有效大小更大。

### **2.2 模型架構**

* Qwen2 系列基本上是基於 Transformer 架構的大型語言模型，其特點是具有因果掩碼的自注意力機制。具體來說，這個系列包括 4 種規模的密集語言模型（dense language）和一個專家混合 （MoE） 模型。

#### **2.2.1 Qwen2 密集模型**

* Qwen2 密集模型的架構包含多個 Transformer 層，每一層都配備了因果注意力機制（causal attention mechanisms）和前饋神經網絡 (FFN)。
* Qwen2 與 Qwen 的主要區別如下：
  * **分組查詢注意力：** 採用分組查詢注意力 (GQA) 代替傳統的多頭注意力 (MHA)。GQA 優化了推理過程中的 KV 緩存使用，顯著提高了吞吐量。
  * **帶有 YARN 的雙塊注意力：** 為了擴展上下文窗口，阿里巴巴實現了雙塊注意力 (DCA)，它將長序列分割成可管理長度的塊。如果輸入可以在一個塊中處理，DCA 會產生與原始注意力相同的結果。否則，DCA 有助於有效捕獲塊內和塊之間詞之間的相對位置信息，從而提高長上下文性能。此外，Qwen2 還採用 YARN 來重新調整注意力權重，以更好地進行長度外推。
* Qwen2 沿用了 Qwen 的做法，使用 SwiGLU 進行激活，使用旋轉位置嵌入 (RoPE) 進行位置嵌入，使用 QKV 偏差進行注意力計算，使用 RMSNorm 和預歸一化來提高訓練穩定性。

#### **2.2.2 Qwen2 專家混合模型**

* Qwen2 MoE 模型的架構與 Qwen1.5-MoE-A2.7B 的架構非常相似。
* 作為原始 FFN 的替代方案，MoE FFN 由 n 個單獨的 FFN 組成，每個 FFN 都充當一個專家。
*   以下介紹 Qwen2 MoE 的關鍵設計考慮因素：

    * **專家粒度（**Expert Granularity**）：** MoE 模型和密集模型之間的主要結構差異在於，MoE 層包含多個 FFN，每個 FFN 都充當一個獨立的專家。因此，從密集架構過渡到 MoE 架構的一個簡單策略是將每個專家的參數設置為與原始密集模型中單個 FFN 的參數相等。Qwen2 模型採用細粒度專家，創建規模更小的專家，同時啟用更多專家。在專家總參數和激活參數相同的情況下，細粒度專家提供了更豐富的專家組合。通過利用這些細粒度專家，Qwen2 MoE 促進了更多樣化和動態的專家利用，從而提高了整體性能和適應性。
    * **專家路由（**Expert Routing**）：** 專家路由機制的設計對於提高 MoE 模型的性能至關重要。在 MoE 層中集成共享專家和路由特定專家已成為一種明顯的趨勢。Qwen2 採用了這種方法，因為它促進了共享專家在各種任務中的應用，同時保留了其他專家在特定路由場景中的選擇性使用。引入共享專家和專用專家為開發 MoE 路由機制提供了一種更具適應性和效率的方法。

    <figure><img src="../../.gitbook/assets/image (6).png" alt="" width="563"><figcaption></figcaption></figure>

    * **專家初始化（**Expert Initialization**）：** Qwen2 以類似於升級的方式初始化專家，利用密集模型的權重。相比之下，阿里巴巴的方法強調細粒度專家之間的多樣性，以增強模型的表示廣度。

#### **2.2.3 模型配置**

* Qwen2 系列由 5 種規模的模型組成，分別是 Qwen2-0.5B、Qwen2-1.5B、Qwen2-7B、Qwen2-57B-A14B 和 Qwen2-72B。表 1 列出了超參數和重要信息，例如預訓練詞的數量。
* 值得注意的是，Qwen2 模型的每個詞的鍵值 (KV) 大小相對於 Qwen1.5 模型要小得多。這一特性轉化為更低的內存佔用，這在長上下文推理任務中特別有利。

## **3. 預訓練**

### **3.1 預訓練數據**

* Qwen2 模型的預訓練涉及開發一個新的、大規模、高質量的多語言數據集。該數據集是對之前 Qwen 和 Qwen1.5 模型中使用的語料庫的改進，在幾個關鍵領域提高了預訓練數據的規模、質量和多樣性：
  * **質量提升（**Quality Enhancement**）：** 過濾算法通過額外的基於啟發式和基於模型的方法進行了改進，包括使用 Qwen 模型來過濾掉低質量數據。此外，這些模型還用於合成高質量的預訓練數據。
  * **數據擴展（**Data Expansion**）：** 與 Qwen1.5 相比，阿里巴巴收集了更大體量的程式碼、數學和多語言數據，增強了模型在各自領域的能力。這個新的數據集支持大約 30 種語言，例如英語、中文、西班牙語、法語、德語、阿拉伯語、俄語、韓語、日語、泰語和越南語。
  * **分佈改進：** 為了確保模型學習類似於人類學習的分佈，阿里巴巴在縮小規模的模型上進行實驗，以優化來自不同來源和領域的數據混合。
* 基於這些增強功能，預訓練數據從 Qwen1.5 中的 3TB 個詞擴展到 7TB 個詞，所有 Qwen2 密集模型（Qwen2-0.5B 使用 12 萬億個詞）都經過這個超過 7 萬億個詞的大規模數據集的預訓練，MoE模型額外使用 4.5 TB token 的預訓練，符合升級循環（upcycling）的原則。
* 與之前的 Qwen 模型類似，高質量的多任務指令數據被集成到 Qwen2 預訓練過程中，以增強上下文學習和指令遵循能力。

### **3.2 長上下文訓練**

* 為了增強 Qwen2 的長上下文能力，阿里巴巴在預訓練的最後階段將上下文長度從 4,096 個詞增加到 32,768 個詞。
* 為了充分利用模型的長度外推潛力，Qwen2 採用了 YARN 機制和雙塊注意力（Dual Chunk Attention）機制。這些策略使模型能夠在保持高性能的同時處理多達 131,072 個詞的序列。

## **4. 後續訓練**

* 在經過廣泛的大規模預訓練之後，阿里巴巴對 Qwen2 進行了後續訓練階段。這個過程對於提高其在編碼、數學、邏輯推理、指令遵循和多語言理解等廣泛領域的熟練程度至關重要。
* 與嚴重依賴大量人工監督的傳統方法不同，Qwen2 的方法側重於以最少的人工標註實現可擴展的對齊。具體來說，阿里巴巴研究了獲取用於監督微調 (SFT) 和從人類反饋中強化學習 (RLHF) 的高質量演示和偏好數據的方法，旨在最大程度地減少對人工標記的需求，同時最大程度地提高數據的質量和可靠性。

### **4.1 後續訓練數據**

#### **4.1.1 協作數據標註**

* **自動本體提取（**Automatic Ontology Extraction**）：** 該過程首先應用開放集細粒度標記器 InsTag 從大規模指令語料庫中提取底層本體。隨後的人工優化確保了提取的本體的準確性。
* **指令選擇（**Instruction Selection**）：** 根據標籤多樣性、語義豐富度、複雜性和意圖完整性等標準，選擇一組具有代表性的指令。
* **指令演化（**Instruction Evolution**）：** 為了豐富指令數據集，採用了一種自演化策略，提示 Qwen 模型向現有指令添加約束或要求，從而增加其複雜性，並確保數據集中具有多樣化的難度級別。
* **人工標註（**Human Annotation**）：** 使用不同的生成策略和不同規模的 Qwen 模型獲得對一條指令的多個響應。標註者根據自己的偏好對這些響應進行排序，確保最佳響應滿足既定標準，從而產生演示數據和偏好數據。

#### **4.1.2 自動數據合成**

* **拒絕抽樣（**Rejection Sampling**）：** 對於數學或具有明確最終答案的類似任務，應用拒絕抽樣來提高解決方案的質量。大型語言模型 (LLM) 的任務是為每條指令生成多個響應，即推理路徑。導致準確結論並被模型認為合理的路径將被保留，作為演示數據。偏好數據是通過對比正確和錯誤的路徑生成的。
* **執行反饋（**Execution Feedback**）：** 對於編碼任務，LLM 用於生成解決方案和相關的測試用例。通過編譯這些解決方案並針對測試用例執行它們來評估其有效性，從而創建演示數據和偏好數據。這種方法也適用於評估指令遵循。
* **數據再利用（**Data Repurposing**）：** 對於沒有經過專門培訓的標註者來說，在文學寫作任務中創造出熟練的響應具有挑戰性。為了應對這個問題，阿里巴巴從公共領域收集了高質量的文學作品，並採用 LLM 來開發不同詳細程度的指令。這些指令與原始作品配對，作為演示數據。
* **憲法反饋（**Constitutional Feedback**）：** 憲法 AI 是指指導 LLM 根據預先定義的原則集生成響應的過程。為了確保遵守安全性和價值觀等準則，阿里巴巴編制了一個憲法數據集。該數據集描述了要遵循的原則和要避免的原則。它被用於指示 LLM 產生符合或偏離這些準則的響應，作為演示數據和偏好數據的參考。

### **4.2 監督微調**

* 阿里巴巴收集了一個包含 500,000 多個示例的大型指令數據集，涵蓋指令遵循、編碼、數學、邏輯推理、角色扮演、多語言和安全性等技能，長度為 32,768 個 tokens。

### **4.3 從人類反饋中強化學習**

* Qwen2 的 RLHF 訓練方案包括兩個順序階段：離線訓練和在線訓練。
  * 離線訓練階段：使用預編譯的偏好資料集 P 透過直接偏好最佳化來最大化 $$y_i^+$$ 和 $$y_i^-$$ 之間的可能性差異。&#x20;
  * 線上訓練階段：模型利用獎勵模型進行即時回饋，即時迭代完善其效能。

## **5. 評估**

* 為了全面評估 Qwen2 模型（包括基礎模型和指令微調模型），阿里巴巴實施了一個全面的評估協議。該協議檢查了一系列能力，包括一般知識理解、語言理解、生成、編碼、數學、推理和其他專業領域。

### **5.1 基礎語言模型**

* 阿里巴巴在基準數據集上評估模型的知識和基本能力，並應用多語言基準數據集來評估它們對語言的支持。由於模型大小有多種，因此將它們與規模相似或更大的最先進 (SOTA) 模型進行比較。

#### **5.1.1 核心能力**

* 評估基礎語言模型核心能力的常見做法是使用少樣本或零樣本提示進行基準數據集評估。評估主要集中在模型在自然語言理解、一般問答、程式碼、數學、科學知識、推理等方面的性能。

<figure><img src="../../.gitbook/assets/image (7).png" alt="" width="563"><figcaption></figcaption></figure>

* 評估 MoE 模型

<figure><img src="../../.gitbook/assets/image (8).png" alt="" width="530"><figcaption></figcaption></figure>

### **5.2 指令微調模型**

#### **5.2.1 開放基準測試評估**

* 為了全面評估指令微調模型的質量，阿里巴巴編制了自動評估和人工評估，以評估其能力和人類偏好。為了評估基本能力，阿里巴巴應用了預訓練模型評估中類似的數據集，這些數據集針對自然語言理解、編碼、數學和推理。

#### **5.2.2 內部自動評估**

* 儘管有許多開放的基準數據集可用於評估，但阿里巴巴認為，這些數據集還遠遠不足以完全理解 LLM 的能力。具體來說，阿里巴巴製作了一系列內部數據集，用於評估模型的不同能力，例如知識理解、文本生成、編碼等。評估採用中文和英文兩種語言。結果分別彙總在表 10 和表 11 中。

#### **5.2.3 長上下文能力**

* 採用了三種評估長上下文能力的方法：大海撈針 (NIAH)、NeedleBench 和 LV-Eval。

<figure><img src="../../.gitbook/assets/image (9).png" alt="" width="530"><figcaption></figcaption></figure>

#### **5.2.4 多語言評估**

* 對於多語言評估，阿里巴巴實施了一項全面的人工評估，以評估多語言能力。具體來說，阿里巴巴設計了不同的測試用例來評估大型語言模型的不同能力，並且有許多語言的測試用例。對於標註者，阿里巴巴為每種語言邀請了一名精通該語言的專業標註者進行評估。對於每個測試用例，標註者使用 1 到 5 的分數對模型的響應進行評分。

#### **5.2.5 安全性和責任**

* 具有公開訪問權重的 LLM 有效地加速了研究及其應用的發展。此外，阿里巴巴認為，構建安全可靠的 LLM 至關重要，這樣才能顯著減輕人工智能技術濫用的影響。
* 阿里巴巴實施了一項多語言安全評估，以不同語言測試 LLM。具體來說，阿里巴巴評估模型在非法行為、欺詐、色情和隱私等主題方面的安全性能。阿里巴巴收集了容易被越獄的提示，並使用它們來測試模型是否可以通過拒絕來提供安全的響應。

#### **5.2.6 污染分析**

* 對於大型語言模型來說，什麼算作污染以及如何進行污染分析仍然是一個活躍的研究領域。為了評估洩漏資料對測試效能的潛在影響，依照OpenAI（2023）建構了嚴格的無污染測試集，然後估計剩餘污染對基準測試分數的影響程度。

## **6. 結論**

* 這篇技術報告介紹了 Qwen2 系列模型，這是一套通用的基礎語言模型和指令微調語言模型，參數範圍從 5 億到 720 億，包括密集架構和專家混合架構的模型。
* Qwen2 在語言理解、生成、多語言能力、編碼、數學和推理等多項基準測試中，表現優於之前的開源模型，尤其是其前身 Qwen1.5，並展現出與專有模型相比具有競爭力的性能。
* 在此次更新中，阿里巴巴額外關注了長上下文、多語言、編碼、數學能力以及安全性和責任。
* 為了促進社區的創新和可訪問性，阿里巴巴公開提供了 Qwen2 模型權重，這使得研究人員和開發者能夠在各種應用和研究項目中充分利用 Qwen2 的潛力。
